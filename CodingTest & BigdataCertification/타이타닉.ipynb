{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66fdfdc7",
   "metadata": {},
   "source": [
    "# 보여주기 할려면 이거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96ccd5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8862359550561798"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def exam_data_load(df, target, id_name=\"\", null_name=\"\"):\n",
    "    if id_name == \"\":\n",
    "        df = df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "        id_name = 'id'\n",
    "    else:\n",
    "        id_name = id_name\n",
    "    \n",
    "    if null_name != \"\":\n",
    "        df[df == null_name] = np.nan\n",
    "    \n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=2021)\n",
    "    \n",
    "    y_train = X_train[[id_name, target]]\n",
    "    X_train = X_train.drop(columns=[target])\n",
    "\n",
    "    \n",
    "    y_test = X_test[[id_name, target]]\n",
    "    X_test = X_test.drop(columns=[target])\n",
    "    return X_train, X_test, y_train, y_test \n",
    "    \n",
    "df = pd.read_csv(\"C:/Users/SuperUser/Desktop/data/titanic_train.csv\")\n",
    "X_train, X_test, y_train, y_test = exam_data_load(df, target='Survived', id_name='PassengerId')\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "### 여기서부터 보면 될듯,,? 간단한 전처리 및 학습 \n",
    "\n",
    "col = ['Pclass','Sex','SibSp','Fare','Embarked']\n",
    "y = y_train['Survived']\n",
    "X_train = pd.get_dummies(X_train[col])\n",
    "test = pd.get_dummies(X_test[col])\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 7, n_estimators=200, random_state=2022)\n",
    "model.fit(X_train,y)\n",
    "pred = model.predict(test)\n",
    "model.score(X_train,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a523d5ea",
   "metadata": {},
   "source": [
    "# 개열심히 분석할려면 이거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9030dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 11), (179, 11), (712, 2), (179, 2))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def exam_data_load(df, target, id_name=\"\", null_name=\"\"):\n",
    "    if id_name == \"\":\n",
    "        df = df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "        id_name = 'id'\n",
    "    else:\n",
    "        id_name = id_name\n",
    "    \n",
    "    if null_name != \"\":\n",
    "        df[df == null_name] = np.nan\n",
    "    \n",
    "    X_train, X_test = train_test_split(df, test_size=0.2, random_state=2021)\n",
    "    \n",
    "    y_train = X_train[[id_name, target]]\n",
    "    X_train = X_train.drop(columns=[target])\n",
    "\n",
    "    \n",
    "    y_test = X_test[[id_name, target]]\n",
    "    X_test = X_test.drop(columns=[target])\n",
    "    return X_train, X_test, y_train, y_test \n",
    "    \n",
    "df = pd.read_csv(\"C:/Users/SuperUser/Desktop/data/titanic_train.csv\")\n",
    "x_train, x_test, y_train, y_test = exam_data_load(df, target='Survived', id_name='PassengerId')\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d98e5638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 90 to 116\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  712 non-null    int64  \n",
      " 1   Pclass       712 non-null    int64  \n",
      " 2   Name         712 non-null    object \n",
      " 3   Sex          712 non-null    object \n",
      " 4   Age          575 non-null    float64\n",
      " 5   SibSp        712 non-null    int64  \n",
      " 6   Parch        712 non-null    int64  \n",
      " 7   Ticket       712 non-null    object \n",
      " 8   Fare         712 non-null    float64\n",
      " 9   Cabin        170 non-null    object \n",
      " 10  Embarked     711 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 66.8+ KB\n"
     ]
    }
   ],
   "source": [
    "x_train.info() # 보면 데이터 타입이 int형이랑 object 형 있는거 확인하고 null 값 확인하고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24bc7197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            137\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          542\n",
       "Embarked         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isnull().sum() # null 값 확인 보면 AGE 랑 cabin, Embarked  null 값 있는거 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ab26b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 210 to 45\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  179 non-null    int64  \n",
      " 1   Pclass       179 non-null    int64  \n",
      " 2   Name         179 non-null    object \n",
      " 3   Sex          179 non-null    object \n",
      " 4   Age          139 non-null    float64\n",
      " 5   SibSp        179 non-null    int64  \n",
      " 6   Parch        179 non-null    int64  \n",
      " 7   Ticket       179 non-null    object \n",
      " 8   Fare         179 non-null    float64\n",
      " 9   Cabin        34 non-null     object \n",
      " 10  Embarked     178 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "x_test.info() # 검증용 데이터도 동일한 과정을거친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ada1f073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            137\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          542\n",
       "Embarked         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e459d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에 확인해보면 Name 컬럼이랑 Id 값은 학습에 도움이 안되기 때문에 버려!\n",
    "\n",
    "x_train.drop(columns=['PassengerId','Name'],inplace=True)\n",
    "x_test.drop(columns=['PassengerId','Name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66d5a58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sex', 'Ticket', 'Cabin', 'Embarked'], dtype='object')\n",
      "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "str_col = x_train.select_dtypes('object').columns\n",
    "num_col = x_train.select_dtypes(exclude='object').columns\n",
    "print(str_col)\n",
    "print(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b899da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null 값 처리하기\n",
    "# 일단 수치형만 Null 값 처리해주면 될거야. 범주형은 one-hot encoding 해주거나 Labelencoder 해주면 알아서 \n",
    "# 처리 해줄거야,,아마도\n",
    "\n",
    "x_train['Age'].fillna(X_train['Age'].mean(),inplace=True)\n",
    "x_test['Age'].fillna(X_test['Age'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50295179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 시켜주기\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "\n",
    "\n",
    "#수치형 데이터 정규화 (정규화 종류중 표준정규화 사용)\n",
    "scaler = StandardScaler()\n",
    "x_train[num_col] = scaler.fit_transform(x_train[num_col])\n",
    "x_test[num_col] = scaler.fit_transform(x_test[num_col])\n",
    "\n",
    "\n",
    "#범주형 데이터 정규화 시키기 (1)\n",
    "# 근데 보통 이거 사용하는게 맘 편해\n",
    "le = LabelEncoder()\n",
    "for col in str_col:\n",
    "    x_train[col] = le.fit_transform(x_train[col])\n",
    "    x_test[col] = le.fit_transform(x_test[col])\n",
    "\n",
    "    \n",
    "# 범주형 데이터 정규화 시키기 (2)\n",
    "# 얘는 범주형만 알아서 0,1 로 구분시켜주는 코드\n",
    "# X_train = pd.get_dummies(X_train)\n",
    "# X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f014c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기는 모델 자체 평가 지표\n",
      "RandomForestClassifier : 0.8251748251748252\n",
      "DecisionTreeClassifier : 0.8251748251748252\n",
      "XGBClassifier : 0.8461538461538461\n",
      "--------------------------------------------------------------------------------\n",
      "여기는 roc_auc_score\n",
      "RandomForestClassifier roc_auc_score: 0.8914256198347108\n",
      "DecisionTreeClassifier roc_auc_score: 0.7056818181818182\n",
      "XGBClassifier roc_auc_score: 0.8989669421487604\n",
      "--------------------------------------------------------------------------------\n",
      "여기는 모델 혼동행렬표에 따른 각각의 평가지표\n",
      "RandomForestClassifier : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86        88\n",
      "           1       0.76      0.80      0.78        55\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.82      0.82       143\n",
      "weighted avg       0.83      0.83      0.83       143\n",
      "\n",
      "================================================================================\n",
      "DecisionTreeClassifier : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76        88\n",
      "           1       0.62      0.67      0.64        55\n",
      "\n",
      "    accuracy                           0.71       143\n",
      "   macro avg       0.70      0.71      0.70       143\n",
      "weighted avg       0.72      0.71      0.72       143\n",
      "\n",
      "================================================================================\n",
      "XGBClassifier : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        88\n",
      "           1       0.80      0.80      0.80        55\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.84      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이제 모델 학습 시키고 하면 됨\n",
    "\n",
    "y = y_train['Survived'] # survived 예측해야 하니 이거만 호출\n",
    "x_tr,x_te,y_tr,y_te = train_test_split(x_train,y,test_size=0.2,random_state=2022)\n",
    "\n",
    "model_rf = RandomForestClassifier(random_state=2022)\n",
    "model_rf.fit(x_tr,y_tr)\n",
    "pred_rf = model_rf.predict(x_te)\n",
    "proba_rf = model_rf.predict_proba(x_te)\n",
    "score_rf = model_rf.score(x_te,y_te)\n",
    "roc_auc_rf = roc_auc_score(y_te,proba_rf[:,1])\n",
    "\n",
    "model_dt = DecisionTreeClassifier(random_state=2022)\n",
    "model_dt.fit(x_tr,y_tr)\n",
    "pred_dt = model_dt.predict(x_te)\n",
    "proba_dt = model_dt.predict_proba(x_te)\n",
    "score_dt = model_rf.score(x_te,y_te)\n",
    "roc_auc_dt = roc_auc_score(y_te,proba_dt[:,1])\n",
    "\n",
    "model_xg = XGBClassifier(random_state=2022)\n",
    "model_xg.fit(x_tr,y_tr)\n",
    "pred_xg = model_xg.predict(x_te)\n",
    "proba_xg = model_xg.predict_proba(x_te)\n",
    "score_xg = model_xg.score(x_te,y_te)\n",
    "roc_auc_xg = roc_auc_score(y_te,proba_xg[:,1])\n",
    "\n",
    "\n",
    "print('여기는 모델 자체 평가 지표')\n",
    "print(f'RandomForestClassifier : {score_rf}')\n",
    "print(f'DecisionTreeClassifier : {score_dt}')\n",
    "print(f'XGBClassifier : {score_xg}')\n",
    "\n",
    "print('-'*80)\n",
    "print('여기는 roc_auc_score')\n",
    "print(f'RandomForestClassifier roc_auc_score: {roc_auc_rf}')\n",
    "print(f'DecisionTreeClassifier roc_auc_score: {roc_auc_dt}')\n",
    "print(f'XGBClassifier roc_auc_score: {roc_auc_xg}')\n",
    "\n",
    "\n",
    "repot1 = classification_report(y_te,pred_rf)\n",
    "repot2 = classification_report(y_te,pred_dt)\n",
    "repot4 = classification_report(y_te,pred_xg)\n",
    "print('-'*80)\n",
    "print('여기는 모델 혼동행렬표에 따른 각각의 평가지표')\n",
    "print(f'RandomForestClassifier : \\n{repot1}')\n",
    "print('='*80)\n",
    "print(f'DecisionTreeClassifier : \\n{repot2}')\n",
    "print('='*80)\n",
    "print(f'XGBClassifier : \\n{repot4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0c8f6",
   "metadata": {},
   "source": [
    "# 추가 설명\n",
    "\n",
    "이거 모델 ROC_AUC_SCORE는 그 뭐야,,ROC_Curve 그래프에서 면적 값을 의미하는데 1에 가까울수록 모델 성능은 좋은거,,추가 자료는 구글링 해봐 ㅋㅋ귀찮아,,,\n",
    "\n",
    "혼동행렬표 \n",
    " - AccuracyScore- 정확도 : 전체 관측치 중 실제값과 예측치가 일치한 정도를 나타낸다. 정분류율은 범주의 분포가 균형을 이룰 때 효과적인 평가지표이다.\n",
    " - precision - 정밀도 : 모델의 예측값이 얼마나 정확하게 예측됐는가 나타내는 지표\n",
    " - recall - 재현율 : 실제 True 인 관측치 중 예측치가 적중한 정도 / 모형의 완정성 평가\n",
    " - f1-score : 정확도와 재현율의 조화평균. 정확도와 재현율에 같은 가중치를 부여하여 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2fbc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
